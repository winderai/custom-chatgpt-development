{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Tg9p0JE63P"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2G5JBkiE50B"
      },
      "outputs": [],
      "source": [
        "##install Falcontune and Falcon-7B model\n",
        "!git clone https://github.com/rmihaylov/falcontune\n",
        "!wget https://huggingface.co/TheBloke/falcon-7b-instruct-GPTQ/resolve/main/gptq_model-4bit-64g.safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v4W-cEbE52w"
      },
      "outputs": [],
      "source": [
        "#install its dependencies\n",
        "!cd falcontune && pip install -r requirements.txt\n",
        "!cd falcontune && python setup.py install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u78_DUqdzGrW"
      },
      "source": [
        "# Fine-tune Falcon-7B on toy dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa0AzwyozGPX"
      },
      "outputs": [],
      "source": [
        "#Get toy dataset\n",
        "!wget https://github.com/gururise/AlpacaDataCleaned/raw/main/alpaca_data_cleaned.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmK1Xn-TzIqG"
      },
      "outputs": [],
      "source": [
        "falcontune finetune \\\n",
        "    --model=falcon-7b-instruct-4bit \\ #Specify the Falcon model\n",
        "    --weights=./gptq_model-4bit-64g.safetensors \\ #Specify model weights\n",
        "    --dataset=./alpaca_data_cleaned.json \\ #choose your own dataset\n",
        "    --data_type=alpaca \\ \n",
        "    --lora_out_dir=./falcon-7b-instruct-4bit-alpaca/ \\ #Specify output directory\n",
        "    --mbatch_size=1 \\ \n",
        "    --batch_size=2 \\ #\n",
        "    --epochs=3 \\ #Specify number of epochs\n",
        "    --lr=3e-4 \\ #Specify learning rate\n",
        "    --cutoff_len=256 \\ \n",
        "    --lora_r=8 \\ #Specify LoRA parameters\n",
        "    --lora_alpha=16 \\\n",
        "    --lora_dropout=0.05 \\\n",
        "    --warmup_steps=5 \\ \n",
        "    --save_steps=50 \\ #Specify how often to save model checkpoints\n",
        "    --save_total_limit=3 \\ #Specify how many checkpoints to save\n",
        "    --logging_steps=5 \\ #Specify how often to log\n",
        "    --target_modules='[\"query_key_value\"]' \\ \n",
        "    --backend=triton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aKvXziTziXY"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_qtyiFzgv2"
      },
      "outputs": [],
      "source": [
        "!falcontune generate \\\n",
        "    --interactive \\  #Specify interactive mode\n",
        "    --model falcon-40b-instruct-4bit \\ #Specify the Falcon model\n",
        "    --weights ./gptq_model-4bit--1g.safetensors \\\n",
        "    --lora_apply_dir falcon-40b-instruct-4bit-alpaca/ \\\n",
        "    --max_new_tokens 50 \\ #Specify how many tokens to generate\n",
        "    --use_cache \\ #Specify whether to use cache\n",
        "    --do_sample \\ \n",
        "    --instruction \"How to prepare pasta?\" \\ #Specify the query\n",
        "    --backend triton "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OOwapqyqWdh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duFhqd15qOev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fm-7DODqOiR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
